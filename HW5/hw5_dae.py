# -*- coding: utf-8 -*-
"""hw5_dAE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UiAA6zl6Ng846nlkrhQ_kGFbFEwytAID
"""

import torch
import torchvision
from torchvision import transforms, datasets
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# downloading data
train = datasets.MNIST(root='./data', train=True, download=True,transform=transforms.Compose([transforms.ToTensor()]))
test = datasets.MNIST(root='./data', train=False, download=True,transform=transforms.Compose([transforms.ToTensor()]))

# Mini batches of batch size 64
trainset = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)
testset = torch.utils.data.DataLoader(test, batch_size=64, shuffle=True)

# DAE
class DAE(nn.Module):
    def __init__(self):
        super(DAE, self).__init__()
        self.fc1 = nn.Linear(784, 400)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(400, 20)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(20, 400)
        self.relu3 = nn.ReLU()
        self.fc4 = nn.Linear(400, 784)
        self.sig1 = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu1(x)
        x = self.fc2(x)
        x = self.relu2(x)
        x = self.fc3(x)
        x = self.relu3(x)
        x = self.fc4(x)
        out = self.sig1(x)
        return out

def training(optimizer, image_f, image_r):
    optimizer.zero_grad()
    # binary cross entropy loss
    Loss = nn.BCELoss()
    loss = Loss(image_f, image_r)
    # back propagation
    loss.backward()
    optimizer.step()
    loss1 = loss.item()*64
    return loss1

def calc_loss(dae, optimizer, data) :
    _, (image, _) = data
    # real image
    image_r = image.view(image.size(0), -1)
    # generating image by adding random noise to input image
    image_f = dae((torch.randn(image_r.size()) * 0.459) + image_r)
    loss = training(optimizer, image_f, image_r)
    return loss

def train_dae(dae, optimizer, loss):
    for epoch in range(10):
        sum1 = 0
        for data in enumerate(trainset):
            dae_loss = calc_loss(dae, optimizer, data)
            sum1 = sum1 + dae_loss
        loss.append(sum1/60000)
    # saving trained model
    torch.save(dae, './hw5_dAE.pth')

def test_dae():
    # Load trained model
    dae = torch.load('./hw5_dAE.pth')
    # 5 original test images
    test_images = next(iter(testset))[0].data[:5].view(5, -1) 
    random_noise = 0.459 * torch.randn(test_images.size())
    # 5 noisy test images
    noisy_test_images = test_images + random_noise
    # reconstructed images from model
    new_images = dae(noisy_test_images)
    # 2x5 grid plotting
    for j in range(5):
        plt.subplot(2, 5, j+1)
        # row 1 with 5 noisy test images
        plt.imshow(noisy_test_images.data[j].reshape(28,28), cmap='gray')
        frame = plt.gca()
        frame.axes.get_xaxis().set_visible(False)
        frame.axes.get_yaxis().set_visible(False)
    for j in range(5):
        plt.subplot(2, 5, j+1+5)
        # row 2 with denoised images
        plt.imshow(new_images.data[j].reshape(28,28), cmap='gray')
        frame = plt.gca()
        frame.axes.get_xaxis().set_visible(False)
        frame.axes.get_yaxis().set_visible(False)
    plt.subplots_adjust(wspace =0, hspace=0, top=0.6)
    plt.show()

def main():
    dae = DAE()
    # Adam as optimizer
    optimizer = optim.Adam(dae.parameters(), lr=0.0002)
    loss = list()
    # training
    train_dae(dae, optimizer, loss)
    plt.plot(loss)
    plt.ylabel("Loss")
    plt.xlabel("Epochs")
    plt.title("Loss vs Epochs")
    plt.show()
    # test the model
    test_dae()

if __name__== "__main__":
    main()