# -*- coding: utf-8 -*-
"""hw2_multi_svm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XceMCyEbQWmjl3wEL0-yCy0u3jKgCEsQ
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from cvxopt import matrix
from cvxopt.solvers import qp,options

#Importing data from dataset
training_data = pd.read_csv('mfeat_train.csv').values
test_data = pd.read_csv('mfeat_test.csv').values

X = training_data[:,1:-1]
y = training_data[:,-1].reshape(-1,1)

X_test = test_data[:,1:-1]
y_test = test_data[:,-1].reshape(-1,1)

#Cross validation function
def cross_validation(k):
    length = X.shape[0]
    position = np.arange(length)
    #position = [0, 1, 2, ..... length]
    #randomly shuffling the position array
    np.random.shuffle(position)
    X_shuffled = dict()
    y_shuffled = dict()
    for i in range(k):
        start_index= i * int(length/k)
        end_index= (i+1) * int(length/k)
        #Saving each of the 10 folds
        X_shuffled[i] = X[position[start_index:end_index],:]
        y_shuffled[i] = y[position[start_index:end_index],:]
    return X_shuffled, y_shuffled

#Function that takes one fold as validation data and combines the other folds to form training data
def get_next_train_valid(X_shuffled, y_shuffled, itr, k):
    X_train = np.zeros((1,X_shuffled[itr].shape[1]))
    y_train = np.zeros((1,y_shuffled[itr].shape[1]))
    X_valid = {}
    y_valid = {}
    for i in range(k):
        if i == itr:
            X_valid = X_shuffled[itr]
            y_valid = y_shuffled[itr]
        else:
            X_train = np.concatenate((X_train, X_shuffled[i]), axis=0)
            y_train = np.concatenate((y_train, y_shuffled[i]), axis=0)
    X_train = np.delete(X_train, 0, axis=0)
    y_train = np.delete(y_train, 0, axis=0)
    return X_train, y_train, X_valid, y_valid

def mnist_svm_train(X1,y1,c,sigma):
  options['show_progress'] = False
  K = np.zeros((X1.shape[0], X1.shape[0]))
  for i in range(X1.shape[0]):
    for j in range(X1.shape[0]):
      K[i,j] = np.exp(-1 * np.square(np.linalg.norm(X1[i]-X1[j])) / (2 * np.square(sigma)))
  P = matrix(np.outer(y1,y1) * K)
  q = matrix(np.ones(X1.shape[0]) * -1)
  G = matrix(np.vstack((np.diag(np.ones(X1.shape[0]) * -1), np.identity(X1.shape[0]))))
  h = matrix(np.hstack((np.zeros(X1.shape[0]), np.ones(X1.shape[0]) * c)))
  A = matrix(y1.reshape(1, -1))
  b = matrix(0.0)
  alpha = np.array(qp(P, q, G, h, A, b)['x'])
  return alpha

# Predicting class
def mnist_svm_predict(X_test, X1, y1, alpha, sigma):
    K = np.zeros((X_test.shape[0],X1.shape[0]))
    for i in range(X_test.shape[0]):
        for j in range(X1.shape[0]):
            K[i,j] = np.exp(-1 * np.square(np.linalg.norm(X_test[i]-X1[j])) / (2 * np.square(sigma)))
    y_predict_class = np.matmul(K, alpha * y1)
    return y_predict_class

# Calculating error rate as no. of misclassified samples/ total no. of samples
def error_rate_calc(y, y_predict_class):
    misclassification = y_predict_class - y
    no_of_misclassified_samples = np.count_nonzero(misclassification)
    total_no_of_samples = len(misclassification)
    return no_of_misclassified_samples/total_no_of_samples

def k_fold_cv(k,c1):
  alphas = list()
  cv_acc = list()
  test_acc = list()
  test_error = list()
  validation_error = list()
  #Calling cross validation function
  X_shuffled, y_shuffled = cross_validation(k)
  for c in c1:
    sigma = c
    for i in range(k):
      alpha1 = list()
      # Getting training and validation data
      X_train, y_train, X_cv, y_cv = get_next_train_valid(X_shuffled, y_shuffled, i, k)
      y_train1 = y_train
      y_predict_class_cv = []
      y_predict_class_test = []
      for j in range(10):
        for k1 in range(len(y_train)):
          if y_train[k1] == j:
            y_train[k1]=1
          else:
            y_train[k1]=-1
        #Training model
        alpha = mnist_svm_train(X_train,y_train,c,sigma)
        #Predicting labels using the model
        label_cv = mnist_svm_predict(X_cv, X_train, y_train, alpha, sigma)
        label_test = mnist_svm_predict(X_test, X_train, y_train, alpha, sigma)
        y_predict_class_cv.append(label_cv.flatten())
        y_predict_class_test.append(label_test.flatten())
        #Storing weights
        alpha1.append(alpha.flatten())
      y_predict_class_cv = np.asarray(y_predict_class_cv)
      yp = []
      for column in y_predict_class_cv.T:
        yp.append(np.argmax(column) + 1)
      yp_cv = np.asarray(yp).reshape(-1,1)
      y_predict_class_test = np.asarray(y_predict_class_test)
      yp1 = []
      for column in y_predict_class_test.T:
        yp1.append(np.argmax(column) + 1)
      yp_test = np.asarray(yp1).reshape(-1,1)
      # Calculation accuracy rates
      cv_acc.append(1 - error_rate_calc(y_cv, yp_cv))
      test_acc.append(1 - error_rate_calc(y_test, yp_test))
      # Storing error rates
      test_error.append(error_rate_calc(y_test, yp_test))
      validation_error.append(error_rate_calc(y_cv, yp_cv))
      y_actu = pd.Series(y_test.flatten(), name='Actual')
      y_pred = pd.Series(yp_test.flatten(), name='Predicted')
      confusion_matrix = pd.crosstab(y_actu, y_pred)
      print(confusion_matrix)
      alpha1 = np.asarray(alpha1)
      alphas.append(alpha1.flatten())
    np.savetxt("weights.txt", np.asarray(alphas))
  print("Validation accuracy =")
  print(cv_acc) 
  print("Test accuracy =")
  print(test_acc)
  return validation_error, test_error


def main():
  #Number of folds in cv
  k=10
  c1 = [0.1]
  cv_error, test_error = k_fold_cv(k, c1)

if __name__== "__main__":
    main()